{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8300a0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmill\\Anaconda3\\envs\\tensorflow25\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\mmill\\Anaconda3\\envs\\tensorflow25\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "C:\\Users\\mmill\\Anaconda3\\envs\\tensorflow25\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.layers import *\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from glob import glob\n",
    "import random\n",
    "\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "W, H, D = 224, 224, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1055203",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8fd5f7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1/102: 100%|█████████████████████████████████████████████████████████████████████████| 388/388 [00:15<00:00, 24.36it/s]\n",
      "2/102: 100%|█████████████████████████████████████████████████████████████████████████| 327/327 [00:13<00:00, 24.33it/s]\n",
      "3/102: 100%|█████████████████████████████████████████████████████████████████████████| 137/137 [00:05<00:00, 24.59it/s]\n",
      "4/102: 100%|█████████████████████████████████████████████████████████████████████████| 148/148 [00:05<00:00, 25.19it/s]\n",
      "5/102: 100%|█████████████████████████████████████████████████████████████████████████| 134/134 [00:05<00:00, 25.33it/s]\n",
      "6/102: 100%|█████████████████████████████████████████████████████████████████████████| 651/651 [00:29<00:00, 22.17it/s]\n",
      "7/102: 100%|███████████████████████████████████████████████████████████████████████| 1308/1308 [00:54<00:00, 23.96it/s]\n",
      "8/102: 100%|███████████████████████████████████████████████████████████████████████| 1186/1186 [00:52<00:00, 22.46it/s]\n",
      "9/102: 100%|█████████████████████████████████████████████████████████████████████████| 359/359 [00:14<00:00, 24.12it/s]\n",
      "10/102: 100%|████████████████████████████████████████████████████████████████████████| 601/601 [00:26<00:00, 22.88it/s]\n",
      "11/102: 100%|████████████████████████████████████████████████████████████████████████| 188/188 [00:08<00:00, 21.60it/s]\n",
      "12/102: 100%|████████████████████████████████████████████████████████████████████████| 715/715 [00:34<00:00, 20.66it/s]\n",
      "13/102: 100%|██████████████████████████████████████████████████████████████████████| 1263/1263 [00:56<00:00, 22.43it/s]\n",
      "14/102: 100%|████████████████████████████████████████████████████████████████████████| 140/140 [00:06<00:00, 21.31it/s]\n",
      "15/102: 100%|████████████████████████████████████████████████████████████████████████| 157/157 [00:06<00:00, 25.21it/s]\n",
      "16/102: 100%|████████████████████████████████████████████████████████████████████████| 119/119 [00:05<00:00, 21.99it/s]\n",
      "17/102: 100%|████████████████████████████████████████████████████████████████████████| 481/481 [00:19<00:00, 25.18it/s]\n",
      "18/102: 100%|██████████████████████████████████████████████████████████████████████| 1040/1040 [00:42<00:00, 24.39it/s]\n",
      "19/102: 100%|████████████████████████████████████████████████████████████████████████| 106/106 [00:04<00:00, 23.68it/s]\n",
      "20/102: 100%|████████████████████████████████████████████████████████████████████████| 308/308 [00:14<00:00, 21.85it/s]\n",
      "21/102: 100%|████████████████████████████████████████████████████████████████████████| 589/589 [00:25<00:00, 22.85it/s]\n",
      "22/102: 100%|████████████████████████████████████████████████████████████████████████| 269/269 [00:10<00:00, 24.59it/s]\n",
      "23/102: 100%|████████████████████████████████████████████████████████████████████████| 184/184 [00:08<00:00, 22.29it/s]\n",
      "24/102: 100%|████████████████████████████████████████████████████████████████████████| 160/160 [00:06<00:00, 23.06it/s]\n",
      "25/102: 100%|████████████████████████████████████████████████████████████████████████| 396/396 [00:16<00:00, 23.84it/s]\n",
      "26/102: 100%|████████████████████████████████████████████████████████████████████████| 268/268 [00:10<00:00, 24.62it/s]\n",
      "27/102: 100%|████████████████████████████████████████████████████████████████████████| 715/715 [00:30<00:00, 23.57it/s]\n",
      "28/102: 100%|████████████████████████████████████████████████████████████████████████| 179/179 [00:07<00:00, 25.04it/s]\n",
      "29/102: 100%|████████████████████████████████████████████████████████████████████████| 454/454 [00:19<00:00, 23.47it/s]\n",
      "30/102: 100%|████████████████████████████████████████████████████████████████████████| 551/551 [00:23<00:00, 22.97it/s]\n",
      "31/102: 100%|████████████████████████████████████████████████████████████████████████| 108/108 [00:04<00:00, 24.54it/s]\n",
      "32/102: 100%|████████████████████████████████████████████████████████████████████████| 463/463 [00:18<00:00, 24.38it/s]\n",
      "33/102: 100%|████████████████████████████████████████████████████████████████████████| 212/212 [00:09<00:00, 21.82it/s]\n",
      "34/102: 100%|████████████████████████████████████████████████████████████████████████| 117/117 [00:04<00:00, 25.36it/s]\n",
      "35/102: 100%|████████████████████████████████████████████████████████████████████████| 304/304 [00:13<00:00, 21.88it/s]\n",
      "36/102: 100%|████████████████████████████████████████████████████████████████████████| 944/944 [00:43<00:00, 21.94it/s]\n",
      "37/102: 100%|██████████████████████████████████████████████████████████████████████| 1007/1007 [00:41<00:00, 24.54it/s]\n",
      "38/102: 100%|████████████████████████████████████████████████████████████████████████| 586/586 [00:23<00:00, 24.71it/s]\n",
      "39/102: 100%|██████████████████████████████████████████████████████████████████████| 1071/1071 [00:45<00:00, 23.69it/s]\n",
      "40/102: 100%|████████████████████████████████████████████████████████████████████████| 674/674 [00:29<00:00, 23.15it/s]\n",
      "41/102: 100%|████████████████████████████████████████████████████████████████████████| 263/263 [00:10<00:00, 24.14it/s]\n",
      "42/102: 100%|████████████████████████████████████████████████████████████████████████| 256/256 [00:10<00:00, 24.90it/s]\n",
      "43/102: 100%|████████████████████████████████████████████████████████████████████████| 115/115 [00:04<00:00, 24.29it/s]\n",
      "44/102: 100%|████████████████████████████████████████████████████████████████████████| 128/128 [00:05<00:00, 23.46it/s]\n",
      "45/102: 100%|████████████████████████████████████████████████████████████████████████| 205/205 [00:08<00:00, 23.78it/s]\n",
      "46/102: 100%|████████████████████████████████████████████████████████████████████████| 260/260 [00:11<00:00, 22.02it/s]\n",
      "47/102: 100%|████████████████████████████████████████████████████████████████████████| 257/257 [00:11<00:00, 22.87it/s]\n",
      "48/102: 100%|██████████████████████████████████████████████████████████████████████████| 54/54 [00:02<00:00, 24.82it/s]\n",
      "49/102: 100%|████████████████████████████████████████████████████████████████████████| 112/112 [00:04<00:00, 23.09it/s]\n",
      "50/102: 100%|████████████████████████████████████████████████████████████████████████| 427/427 [00:18<00:00, 23.58it/s]\n",
      "51/102: 100%|████████████████████████████████████████████████████████████████████████| 251/251 [00:11<00:00, 21.77it/s]\n",
      "52/102: 100%|██████████████████████████████████████████████████████████████████████████| 88/88 [00:03<00:00, 22.45it/s]\n",
      "53/102: 100%|████████████████████████████████████████████████████████████████████████| 178/178 [00:07<00:00, 24.69it/s]\n",
      "54/102: 100%|██████████████████████████████████████████████████████████████████████████| 79/79 [00:03<00:00, 20.94it/s]\n",
      "55/102: 100%|████████████████████████████████████████████████████████████████████████| 191/191 [00:08<00:00, 21.98it/s]\n",
      "56/102: 100%|██████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 24.61it/s]\n",
      "57/102: 100%|████████████████████████████████████████████████████████████████████████| 354/354 [00:14<00:00, 24.10it/s]\n",
      "58/102: 100%|████████████████████████████████████████████████████████████████████████| 285/285 [00:12<00:00, 23.48it/s]\n",
      "59/102: 100%|██████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 24.61it/s]\n",
      "60/102: 100%|████████████████████████████████████████████████████████████████████████| 142/142 [00:05<00:00, 24.92it/s]\n",
      "61/102: 100%|████████████████████████████████████████████████████████████████████████| 251/251 [00:11<00:00, 22.16it/s]\n",
      "62/102: 100%|████████████████████████████████████████████████████████████████████████| 161/161 [00:06<00:00, 24.89it/s]\n",
      "63/102: 100%|██████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 25.03it/s]\n",
      "64/102: 100%|██████████████████████████████████████████████████████████████████████████| 73/73 [00:02<00:00, 24.55it/s]\n",
      "65/102: 100%|████████████████████████████████████████████████████████████████████████| 356/356 [00:16<00:00, 21.30it/s]\n",
      "66/102: 100%|████████████████████████████████████████████████████████████████████████| 289/289 [00:12<00:00, 23.66it/s]\n",
      "67/102: 100%|████████████████████████████████████████████████████████████████████████| 200/200 [00:08<00:00, 22.56it/s]\n",
      "68/102: 100%|████████████████████████████████████████████████████████████████████████| 168/168 [00:07<00:00, 23.65it/s]\n",
      "69/102: 100%|██████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 25.68it/s]\n",
      "70/102: 100%|████████████████████████████████████████████████████████████████████████| 100/100 [00:04<00:00, 24.29it/s]\n",
      "71/102: 100%|████████████████████████████████████████████████████████████████████████| 148/148 [00:05<00:00, 25.34it/s]\n",
      "72/102: 100%|████████████████████████████████████████████████████████████████████████| 196/196 [00:08<00:00, 23.71it/s]\n",
      "73/102: 100%|██████████████████████████████████████████████████████████████████████████| 33/33 [00:01<00:00, 25.76it/s]\n",
      "74/102: 100%|████████████████████████████████████████████████████████████████████████| 222/222 [00:09<00:00, 24.34it/s]\n",
      "75/102: 100%|████████████████████████████████████████████████████████████████████████| 597/597 [00:24<00:00, 24.13it/s]\n",
      "76/102: 100%|████████████████████████████████████████████████████████████████████████| 221/221 [00:08<00:00, 25.77it/s]\n",
      "77/102: 100%|████████████████████████████████████████████████████████████████████████| 342/342 [00:14<00:00, 24.25it/s]\n",
      "78/102: 100%|██████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 24.15it/s]\n",
      "79/102: 100%|████████████████████████████████████████████████████████████████████████| 257/257 [00:10<00:00, 25.61it/s]\n",
      "80/102: 100%|████████████████████████████████████████████████████████████████████████| 369/369 [00:14<00:00, 24.87it/s]\n",
      "81/102: 100%|████████████████████████████████████████████████████████████████████████| 594/594 [00:29<00:00, 20.12it/s]\n",
      "82/102: 100%|████████████████████████████████████████████████████████████████████████| 113/113 [00:04<00:00, 24.57it/s]\n",
      "83/102: 100%|██████████████████████████████████████████████████████████████████████████| 77/77 [00:02<00:00, 25.94it/s]\n",
      "84/102: 100%|██████████████████████████████████████████████████████████████████████████| 89/89 [00:03<00:00, 25.95it/s]\n",
      "85/102: 100%|████████████████████████████████████████████████████████████████████████| 174/174 [00:06<00:00, 25.22it/s]\n",
      "86/102: 100%|████████████████████████████████████████████████████████████████████████| 100/100 [00:03<00:00, 25.91it/s]\n",
      "87/102: 100%|████████████████████████████████████████████████████████████████████████| 452/452 [00:17<00:00, 25.15it/s]\n",
      "88/102: 100%|████████████████████████████████████████████████████████████████████████| 360/360 [00:14<00:00, 24.28it/s]\n",
      "89/102: 100%|████████████████████████████████████████████████████████████████████████| 132/132 [00:05<00:00, 25.18it/s]\n",
      "90/102: 100%|██████████████████████████████████████████████████████████████████████████| 71/71 [00:02<00:00, 25.82it/s]\n",
      "91/102: 100%|████████████████████████████████████████████████████████████████████████| 253/253 [00:09<00:00, 25.77it/s]\n",
      "92/102: 100%|████████████████████████████████████████████████████████████████████████| 551/551 [00:23<00:00, 23.14it/s]\n",
      "93/102: 100%|████████████████████████████████████████████████████████████████████████| 116/116 [00:04<00:00, 24.25it/s]\n",
      "94/102: 100%|████████████████████████████████████████████████████████████████████████| 186/186 [00:07<00:00, 25.42it/s]\n",
      "95/102: 100%|██████████████████████████████████████████████████████████████████████| 1583/1583 [01:03<00:00, 24.94it/s]\n",
      "96/102: 100%|██████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 24.78it/s]\n",
      "97/102: 100%|██████████████████████████████████████████████████████████████████████████| 72/72 [00:02<00:00, 24.90it/s]\n",
      "98/102: 100%|████████████████████████████████████████████████████████████████████████| 566/566 [00:23<00:00, 24.09it/s]\n",
      "99/102: 100%|████████████████████████████████████████████████████████████████████████| 119/119 [00:04<00:00, 25.51it/s]\n",
      "100/102: 100%|███████████████████████████████████████████████████████████████████████| 437/437 [00:18<00:00, 24.10it/s]\n",
      "101/102: 100%|███████████████████████████████████████████████████████████████████████| 264/264 [00:11<00:00, 23.18it/s]\n",
      "102/102: 100%|███████████████████████████████████████████████████████████████████████| 464/464 [00:19<00:00, 23.90it/s]\n"
     ]
    }
   ],
   "source": [
    "encodings = []\n",
    "path = r'F:\\hac\\custom_dataset'\n",
    "ids = os.listdir(path)\n",
    "for index, i in enumerate(ids[:]):\n",
    "    encodings.append([])\n",
    "    names = os.listdir(os.path.join(path, i))\n",
    "    for k, name in tqdm(enumerate(names), desc=f'{index + 1}/{len(ids)}', total=len(names)):\n",
    "        img = image.load_img(os.path.join(path, i, name), target_size=(W,H,D))\n",
    "        img_tensor = image.img_to_array(img)\n",
    "        img_tensor = np.expand_dims(img_tensor, axis=0)\n",
    "        img_tensor /= 255.\n",
    "        encodings[index].append(model.predict(img_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5a17dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "names = []\n",
    "\n",
    "for i in ids:\n",
    "    names.extend([os.path.join(i, name) for name in os.listdir(os.path.join(path, i))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "860c98c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = []\n",
    "for arr in encodings:\n",
    "    enc.extend(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67d9dac2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ids</th>\n",
       "      <th>encodings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1\\0.jpg</td>\n",
       "      <td>[[0.039624333, 0.16381598, -0.065188415, -0.08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1\\1.jpg</td>\n",
       "      <td>[[0.042282194, 0.05630434, -0.02977801, -0.020...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1\\10.jpg</td>\n",
       "      <td>[[0.051137805, 0.15925086, -0.07144881, -0.074...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1\\100.jpg</td>\n",
       "      <td>[[0.015196406, 0.018183826, 0.011113236, -0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1\\101.jpg</td>\n",
       "      <td>[[0.021339476, 0.019626467, 0.010315144, -0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33638</th>\n",
       "      <td>99\\95.jpg</td>\n",
       "      <td>[[0.002795008, 0.015622405, 0.0042289738, 0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33639</th>\n",
       "      <td>99\\96.jpg</td>\n",
       "      <td>[[0.005694085, 0.013091637, -0.0011384544, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33640</th>\n",
       "      <td>99\\97.jpg</td>\n",
       "      <td>[[0.002534815, 0.016474051, 0.006219143, 0.018...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33641</th>\n",
       "      <td>99\\98.jpg</td>\n",
       "      <td>[[0.0016266451, 0.021133518, 0.0015703681, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33642</th>\n",
       "      <td>99\\99.jpg</td>\n",
       "      <td>[[-0.0051310724, -0.0031530429, 0.025233338, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33643 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ids                                          encodings\n",
       "0        1\\0.jpg  [[0.039624333, 0.16381598, -0.065188415, -0.08...\n",
       "1        1\\1.jpg  [[0.042282194, 0.05630434, -0.02977801, -0.020...\n",
       "2       1\\10.jpg  [[0.051137805, 0.15925086, -0.07144881, -0.074...\n",
       "3      1\\100.jpg  [[0.015196406, 0.018183826, 0.011113236, -0.00...\n",
       "4      1\\101.jpg  [[0.021339476, 0.019626467, 0.010315144, -0.00...\n",
       "...          ...                                                ...\n",
       "33638  99\\95.jpg  [[0.002795008, 0.015622405, 0.0042289738, 0.01...\n",
       "33639  99\\96.jpg  [[0.005694085, 0.013091637, -0.0011384544, 0.0...\n",
       "33640  99\\97.jpg  [[0.002534815, 0.016474051, 0.006219143, 0.018...\n",
       "33641  99\\98.jpg  [[0.0016266451, 0.021133518, 0.0015703681, 0.0...\n",
       "33642  99\\99.jpg  [[-0.0051310724, -0.0031530429, 0.025233338, 0...\n",
       "\n",
       "[33643 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df['ids'] = names\n",
    "df['encodings'] = enc\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57f77f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('whale_encodings.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c0af8ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33643"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodings = list(df['encodings'])\n",
    "len(encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e952204",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 33643/33643 [00:08<00:00, 3956.47it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(encodings)), total=len(encodings)):\n",
    "    euclidean_distance([encodings[0], encodings[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7c1c14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "735f1e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 102\n",
    "def create_pairs(data, digit_indices):\n",
    "    pairs = []\n",
    "    labels = []\n",
    "    count = 0\n",
    "# Получаем минимальное количество одинаковых чисел в базе\n",
    "    n = min([len(digit_indices[d]) for d in range(num_classes)]) - 1\n",
    "    for d in range(num_classes):\n",
    "        for i in range(n):\n",
    "            # Создаем верную пару\n",
    "            z1, z2 = digit_indices[d][i], digit_indices[d][i + 1]\n",
    "            pairs += [[data[z1], data[z2]]]\n",
    "            # Создаем не верную пару\n",
    "            inc = random.randrange(1, num_classes)\n",
    "            dn = (d + inc) % num_classes\n",
    "            z1, z2 = digit_indices[d][i], digit_indices[dn][i]\n",
    "            # Записываем в список\n",
    "            pairs += [[data[z1], data[z2]]]\n",
    "            labels += [1, 0]\n",
    "    return np.array(pairs), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1291f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6cf9217",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [00:03<00:00, 32.26it/s]\n"
     ]
    }
   ],
   "source": [
    "num_classes = 102\n",
    "path = r'F:\\hac\\custom_dataset'\n",
    "ids = os.listdir(path)\n",
    "ids = [int(i) for i in ids]\n",
    "ids = sorted(ids)\n",
    "x_path = []\n",
    "y = []\n",
    "l_n = [len(os.listdir(os.path.join(path, name))) for name in os.listdir(path)]\n",
    "for i in tqdm(ids):\n",
    "    names = os.listdir(os.path.join(path, str(i)))\n",
    "    names2 = [int(name.split('.')[0]) for name in names]\n",
    "    names = [str(i) + '.jpg' for i in sorted(names2)]\n",
    "#     if len(names) < 100:\n",
    "#         step = 1\n",
    "#     elif 100 < len(names) < 400:\n",
    "#         step = 5\n",
    "#     else:\n",
    "#         step = 10\n",
    "    for j, name in enumerate(names[:]):\n",
    "        for k in range(5):\n",
    "            inc = random.randint(1, l_n[i - 1])\n",
    "            index = (int(i) - 1 + inc) % len(names)\n",
    "            x_path.append([os.path.join(path, str(i), name), os.path.join(path, str(i), names[index])])  # 1   \n",
    "            y.append(1.)\n",
    "            inc = random.randrange(1, num_classes)\n",
    "            dn = (int(i) - 1 + inc) % num_classes\n",
    "            \n",
    "            inc = random.randrange(1, l_n[int(dn)])\n",
    "            index = (int(dn) + inc) % l_n[int(dn)]\n",
    "            x_path.append([os.path.join(path, str(i), name), os.path.join(path, str(dn), name)]) # 0\n",
    "            y.append(0.)\n",
    "#             if k == 1:\n",
    "#                 break\n",
    "#         break\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a1bbfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('x_path.txt', 'w') as file:\n",
    "    for line in x_path:\n",
    "        file.write(str(line[0]) + ' ' + str(line[1]) +'\\n')\n",
    "\n",
    "with open('y.txt', 'w') as file:\n",
    "    for line in y:\n",
    "        file.write(str(line) +'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b65a741",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_path = []\n",
    "y = []\n",
    "with open('x_path.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        x_path.append(line[:-1].split(' '))\n",
    "        \n",
    "with open('y.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        y.append(float(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0815cf0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_path, y, test_size=0.25, random_state=42)\n",
    "# x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c37a537b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vit_keras import vit, utils\n",
    "\n",
    "image_size = W\n",
    "classes = utils.get_imagenet_classes()\n",
    "vit_model = vit.vit_b16(\n",
    "    image_size=image_size,\n",
    "    activation='sigmoid',\n",
    "    pretrained=True,\n",
    "    include_top=False,\n",
    "    pretrained_top=False\n",
    ")\n",
    "classToken = vit_model.layers[3]\n",
    "# vit_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2c45662",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "\n",
    "W, H, D = 224, 224, 3\n",
    "def create_base_network(input_shape):\n",
    "    '''Базовая сеть для совместного использования (eq. to feature extraction).\n",
    "    '''\n",
    "    model = Sequential()\n",
    "#     resnet_model = Sequential()\n",
    "\n",
    "#     pretrained_model= tf.keras.applications.ResNet50(weights=\"imagenet\",\n",
    "#                                                      input_shape=(W, H, D),\n",
    "#                                                      include_top=False,\n",
    "#                                                      pooling='avg'\n",
    "#                                                     )\n",
    "    pretrained_model = vit_model\n",
    "#     for layer in pretrained_model.layers:\n",
    "#             layer.trainable=1\n",
    "#     trainable = False\n",
    "#     for layer in model.layers:\n",
    "#         if layer.name == \"conv5_block1_out\":\n",
    "#             trainable = True\n",
    "#         layer.trainable = trainable\n",
    "\n",
    "    model.add(pretrained_model)\n",
    "    \n",
    "    # Слой свертки\n",
    "#     model.add(Conv2D(32, kernel_size=3, padding='same', activation='relu', input_shape=input_shape))\n",
    "#     model.add(MaxPooling2D(2))\n",
    "    # Слой свертки\n",
    "#     model.add(Conv2D(32, kernel_size=3, padding='same', activation='relu'))\n",
    "#     model.add(MaxPooling2D(2))\n",
    "    \n",
    "#     model.add(Conv2D(32, kernel_size=3, padding='same', activation='relu'))\n",
    "#     model.add(MaxPooling2D(2))\n",
    "    \n",
    "#     model.add(Conv2D(32, kernel_size=3, padding='same', activation='relu'))\n",
    "#     model.add(MaxPooling2D(2))\n",
    "    \n",
    "#     model.add(Conv2D(32, kernel_size=3, padding='same', activation='relu'))\n",
    "#     model.add(MaxPooling2D(2))\n",
    "    \n",
    "#     model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "#     model.add(MaxPooling2D(2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    # Полносвязный слой\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(256))\n",
    "    \n",
    "    \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b542b0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "676ec474",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_shape = (W,H,D)\n",
    "base_network = create_base_network(input_shape)\n",
    "input_a = Input(shape=input_shape, name='input_1')\n",
    "input_b = Input(shape=input_shape, name='input_2')\n",
    "# Получаем вектора признаков\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b229cd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
    "    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n",
    "\n",
    "distance = Lambda(euclidean_distance, output_shape=eucl_dist_output_shape)([processed_a, processed_b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8f13a3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def contrastive_loss(y_true, y_pred):\n",
    "#     '''Контрастная потеря от Hassell-et-al.'06\n",
    "#     http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "#     '''\n",
    "#     margin = 1\n",
    "#     square_pred = K.square(y_pred)\n",
    "#     margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
    "#     return K.mean(y_true * square_pred + (1 - y_true) * margin_square)\n",
    "\n",
    "def contrastive_loss(y, preds, margin=1):\n",
    "    # explicitly cast the true class label data type to the predicted\n",
    "    # class label data type (otherwise we run the risk of having two\n",
    "    # separate data types, causing TensorFlow to error out)\n",
    "    y = tf.cast(y, preds.dtype)\n",
    "    # calculate the contrastive loss between the true labels and\n",
    "    # the predicted labels\n",
    "    squaredPreds = K.square(preds)\n",
    "    squaredMargin = K.square(K.maximum(margin - preds, 0))\n",
    "    loss = K.mean(y * squaredPreds + (1 - y) * squaredMargin)\n",
    "    # return the computed contrastive loss to the calling function\n",
    "    return loss\n",
    "\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    '''Вычислить точность классификации с фиксированным порогом по расстояниям.\n",
    "    '''\n",
    "    return K.mean(K.equal(y_true, K.cast(y_pred < 0.5, y_true.dtype)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "de52cf25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       (None, 256)          86392576    input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 1)            0           sequential_2[0][0]               \n",
      "                                                                 sequential_2[1][0]               \n",
      "==================================================================================================\n",
      "Total params: 86,392,576\n",
      "Trainable params: 86,391,040\n",
      "Non-trainable params: 1,536\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "ename": "InvocationException",
     "evalue": "Program terminated with status: 1. stderr follows: Error: C:\\Users\\mmill\\AppData\\Local\\Temp\\tmpv7lomg06: syntax error in line 13 near '-'\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvocationException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2232/3851272373.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpand_nested\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow25\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[1;34m(model, to_file, show_shapes, show_dtype, show_layer_names, rankdir, expand_nested, dpi)\u001b[0m\n\u001b[0;32m    337\u001b[0m     \u001b[0mextension\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextension\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m   \u001b[1;31m# Save image to disk.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 339\u001b[1;33m   \u001b[0mdot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextension\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    340\u001b[0m   \u001b[1;31m# Return the image as a Jupyter Image object, to be displayed in-line.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m   \u001b[1;31m# Note that we cannot easily detect whether the code is running in a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow25\\lib\\site-packages\\pydotplus\\graphviz.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, path, prog, format)\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1917\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m                 \u001b[0mfobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1919\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1920\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow25\\lib\\site-packages\\pydotplus\\graphviz.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, prog, format)\u001b[0m\n\u001b[0;32m   2028\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2029\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2030\u001b[1;33m             raise InvocationException(\n\u001b[0m\u001b[0;32m   2031\u001b[0m                 'Program terminated with status: %d. stderr follows: %s' % (\n\u001b[0;32m   2032\u001b[0m                     status, stderr_output))\n",
      "\u001b[1;31mInvocationException\u001b[0m: Program terminated with status: 1. stderr follows: Error: C:\\Users\\mmill\\AppData\\Local\\Temp\\tmpv7lomg06: syntax error in line 13 near '-'\r\n"
     ]
    }
   ],
   "source": [
    "model = Model([input_a, input_b], distance)\n",
    "# Оптимизатор будет RMSprop\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "        \n",
    "# Собираем модель\n",
    "model.compile(loss=contrastive_loss, optimizer=opt, metrics=[accuracy])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "tf.keras.utils.plot_model(model, show_shapes=True, expand_nested=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3e6b46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model.layers[2], show_shapes=True, expand_nested=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a6b5672",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen(x, y, batch_size=2):\n",
    "    def get_out(inp):\n",
    "        if inp[0].split('\\\\')[-2] == inp[1].split('\\\\')[-2]:\n",
    "            return 1.\n",
    "        else: \n",
    "            return 0.\n",
    "        \n",
    "    count = 0\n",
    "#     print(x[0])\n",
    "    random.shuffle(x)\n",
    "#     print(x[0])\n",
    "    for k in range(len(x)//batch_size):\n",
    "#         if 1:\n",
    "        try:\n",
    "            batch_paths = x[k*batch_size:(k+1)*batch_size]\n",
    "            batch_input  = []\n",
    "            batch_output = [] \n",
    "            input1 = []\n",
    "            input2 = []\n",
    "            for input_path in batch_paths:\n",
    "                img = image.load_img(input_path[0],\n",
    "                            target_size=(W, H, D))\n",
    "\n",
    "                img_tensor1 = image.img_to_array(img)\n",
    "                img_tensor1 /= 255.\n",
    "\n",
    "                img = image.load_img(input_path[1], \n",
    "                            target_size=(W, H, D))\n",
    "\n",
    "                img_tensor2 = image.img_to_array(img)\n",
    "                img_tensor2 /= 255.\n",
    "\n",
    "                output = get_out(input_path)\n",
    "    #             output = y[count]\n",
    "                count += 1\n",
    "\n",
    "                input1 += [img_tensor1]\n",
    "                input2 += [img_tensor2]\n",
    "#                 batch_input += [[img_tensor1, img_tensor2]]\n",
    "                batch_output += [output]\n",
    "    \n",
    "            batch_input += [input1, input2]\n",
    "            batch_x = np.array( batch_input )\n",
    "    #         batch_y = np.array( batch_output )\n",
    "            batch_y = np.array(batch_output)\n",
    "        except Exception as exc:\n",
    "#             print(exc)\n",
    "            continue\n",
    "#         print(input_path, batch_y)\n",
    "        yield ([np.array(batch_x[0]), np.array(batch_x[1])], batch_y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "667fc302",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "200/200 [==============================] - 142s 709ms/step - loss: 277.6615 - accuracy: 0.3275 - val_loss: 1061.7429 - val_accuracy: 0.3650\n",
      "Epoch 2/1000\n",
      " 76/200 [==========>...................] - ETA: 1:17 - loss: 257.4707 - accuracy: 0.3750"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2232/1984530231.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m model.fit(gen(x_train, y_train, batch_size=2),\n\u001b[0m\u001b[0;32m      2\u001b[0m             \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m             \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow25\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                 _r=1):\n\u001b[0;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow25\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow25\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow25\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow25\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow25\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow25\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(gen(x_train, y_train, batch_size=2),\n",
    "            steps_per_epoch=200,\n",
    "            epochs=1000,\n",
    "            validation_data=gen(x_test, y_test, batch_size=2),\n",
    "            validation_steps=100,\n",
    "             )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1a813fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 20s 202ms/step - loss: 42.5255 - accuracy: 0.5462\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[42.5255126953125, 0.5462499856948853]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(gen(x_test, y_test, batch_size=8), steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "91ad3df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmill\\Anaconda3\\envs\\tensorflow25\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    }
   ],
   "source": [
    "model.save('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf93f81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c3df9d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[41.57617]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img1 = image.load_img(r'F:\\hac\\custom_dataset\\1\\1.jpg', target_size=(W,H,D))\n",
    "img_tensor = image.img_to_array(img1)\n",
    "img_tensor = np.expand_dims(img_tensor, axis=0)\n",
    "img_tensor /= 255.\n",
    "img1 = img_tensor\n",
    "\n",
    "img2 = image.load_img(r'F:\\hac\\custom_dataset\\2\\99.jpg', target_size=(W,H,D))\n",
    "img_tensor = image.img_to_array(img2)\n",
    "img_tensor = np.expand_dims(img_tensor, axis=0)\n",
    "img_tensor /= 255.\n",
    "img2 = img_tensor\n",
    "model.predict([img1, img2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcb32a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
